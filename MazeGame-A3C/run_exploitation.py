from maze_env import Maze
import numpy as np
import a3c
import tensorflow as tf
import time

env = Maze()

S_INFO = env.n_features
A_DIM = env.n_actions
ACTOR_LR_RATE = 0.0001
CRITIC_LR_RATE = 0.001
NN_MODEL = './models/nn_model_ep_8000.ckpt'

with tf.Session() as sess:
    actor = a3c.ActorNetwork(sess,
                             state_dim=S_INFO, action_dim=A_DIM,
                             learning_rate=ACTOR_LR_RATE)
    critic = a3c.CriticNetwork(sess,
                               state_dim=S_INFO,
                               learning_rate=CRITIC_LR_RATE)

    # restore neural network
    nn_model = NN_MODEL
    assert nn_model is not None
    saver = tf.train.Saver()
    saver.restore(sess, nn_model)
    print("Model restored.")

    s = env.reset()
    env.deiconify()
    total_reward = 0.0
    steps = 0
    while True:
        env.render()
        state = s
        action_prob = actor.predict(np.reshape(state, (1, S_INFO)))
        current_a = np.argmax(action_prob)
        s_, reward, done = env.step(current_a)
        s = s_
        total_reward += reward
        steps += 1
        time.sleep(0.5)
        if done:
            break
    print("Game over! Spend {0} steps, total reward = {1}".format(steps, total_reward))

    env.destroy()
